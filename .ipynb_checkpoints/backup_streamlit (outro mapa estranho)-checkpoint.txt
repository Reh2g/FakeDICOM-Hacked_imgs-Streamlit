from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
from keras.layers import Lambda
from keras.utils import CustomObjectScope
from PIL import Image

import streamlit as st
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import random
import cv2
import io
import time
import os

# ----------------- MODELO -----------------
model_path = 'Modelos/model_MobileNet_01p100.keras'
#model_path = 'Modelos/model_MobileNet_5p100.keras'

if not os.path.exists(model_path):
    raise FileNotFoundError(f"Modelo n√£o encontrado em: {os.path.abspath(model_path)}")

def expand_channels(x):
    return tf.stack([x[..., 0]]*3, axis=-1)

modelo_MobileNet = tf.keras.models.load_model(
    model_path,
    custom_objects={'expand_channels': expand_channels},
    safe_mode=False
)

for layer in modelo_MobileNet.layers:
    layer.trainable = False

# ----------------- FUN√á√ïES -----------------
def preprocessar_imagem(imagem):
    img = cv2.resize(imagem, (224, 224))
    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    img = img.astype('float32') / 255.0
    return img

def freq_spec(fshift, imagem, threshold_percent, sigma_blur, add_noise, corner):
    if add_noise:
        threshold = threshold_percent/100.0
        rows, cols = imagem.shape
        noise_size = int(np.sqrt(threshold * rows * cols))
        sigma = sigma_blur

        def gaussian_blur(size, sigma):
            ax = np.linspace(-(size - 1) / 2., (size - 1) / 2., size)
            xx, yy = np.meshgrid(ax, ax)
            kernel = np.exp(-(xx**2 + yy**2) / (2. * sigma**2))
            return kernel / np.sum(kernel)

        blur_kernel = gaussian_blur(noise_size, sigma)

        def blur_patch(spectrum, r_start, c_start):
            patch = spectrum[r_start:r_start+noise_size, c_start:c_start+noise_size]
            if patch.shape != blur_kernel.shape:
                return
            real_blurred = cv2.filter2D(np.real(patch), -1, blur_kernel)
            imag_blurred = cv2.filter2D(np.imag(patch), -1, blur_kernel)
            spectrum[r_start:r_start+noise_size, c_start:c_start+noise_size] = real_blurred + 1j * imag_blurred

        if corner == 0:
            blur_patch(fshift, 0, 0)
        elif corner == 1:
            blur_patch(fshift, 0, cols - noise_size)
        elif corner == 2:
            blur_patch(fshift, rows - noise_size, 0)
        else:
            blur_patch(fshift, rows - noise_size, cols - noise_size)

    magnitude_spectrum_high = 20 * np.log(np.abs(fshift) + 1)

    return fshift, magnitude_spectrum_high

def gerar_heatmap(model, sample_image_exp):
    predictions = model.predict(sample_image_exp)

    st.image(sample_image_exp) # AQUIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
    st.text(predictions)
    
    with tf.GradientTape() as tape:
        # Cria um modelo que nos d√™ a sa√≠da do modelo e as ativa√ß√µes da √∫ltima camada convolucional
        iterate = tf.keras.models.Model([model.input], [model.output, model.get_layer('conv_pw_13').output])
        model_out, last_conv_layer = iterate(sample_image_exp)
        
        # Pegua a sa√≠da da classe predita
        class_out = model_out[:, np.argmax(model_out[0])]
        
        # Registra as opera√ß√µes a serem diferenciadas
        tape.watch(last_conv_layer)
        
        # Calcula os gradientes
        grads = tape.gradient(class_out, last_conv_layer)

    # Verifica se os gradientes foram calculados corretamente
    if grads is None:
        raise ValueError('Gradients could not be computed. Check the model and layer names.')
    
    # M√©dia dos gradientes sobre as dimens√µes espaciais
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    
    # Regulariza√ß√£o dos gradientes
    pooled_grads = tf.where(pooled_grads == 0, tf.ones_like(pooled_grads) * 1e-10, pooled_grads)
    
    # Multiplique as ativa√ß√µes pelos gradientes ponderados e tire a m√©dia
    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer[0]), axis=-1)

    # Normaliza o heatmap se poss√≠vel
    min_value = np.min(heatmap)
    
    # Normaliza o heatmap se poss√≠vel
    max_value = np.max(heatmap)

    # Aplica ReLU para garantir que os valores sejam n√£o-negativos
    heatmap = (heatmap - min_value) / (max_value - min_value)
    heatmap = np.asarray(heatmap)
    heatmap = (heatmap - 1) * (-1)
    
    # Redimensiona o heatmap para o tamanho da imagem de entrada
    heatmap_resized = cv2.resize(heatmap, (sample_image.shape[1], sample_image.shape[0]))
    heatmap_resized = np.uint8(255 * heatmap_resized)

    st.image(heatmap_resized) # AQUIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
    
    # Aplica um mapa de cores
    heatmap_colored = cm.jet(heatmap_resized)[:, :, :3]
    heatmap_colored = np.uint8(heatmap_colored * 255)
    
    # Cria um canal alfa a partir do heatmap redimensionado
    alpha_channel = np.uint8(heatmap_resized)
    heatmap_colored_with_alpha = np.dstack((heatmap_colored, alpha_channel))
    
    # Converte a imagem original para uint8 e RGBA
    sample_image_uint8 = np.uint8(255 * np.squeeze(sample_image))
#   image_rgb = cv2.cvtColor(sample_image_uint8, cv2.COLOR_GRAY2RGB)
#   image_rgba = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2RGBA)
    image_rgba = cv2.cvtColor(sample_image_uint8, cv2.COLOR_RGB2RGBA)
    
    # Combina a imagem original com o heatmap
    alpha_factor = alpha_channel / 255.0
    for c in range(0, 3):
        image_rgba[..., c] = image_rgba[..., c] * (1 - alpha_factor) + heatmap_colored[..., c] * alpha_factor
    
    return image_rgba

def criptografar_imagem(fshift, aes_key):
    inicio = time.perf_counter()
    buffer = io.BytesIO()
    np.save(buffer, fshift)
    buffer.seek(0)
    cipher_aes = AES.new(aes_key, AES.MODE_EAX)
    ciphertext, tag = cipher_aes.encrypt_and_digest(buffer.read())

    out_buffer = io.BytesIO()
    out_buffer.write(cipher_aes.nonce)
    out_buffer.write(tag)
    out_buffer.write(ciphertext)
    out_buffer.seek(0)
    fim = time.perf_counter()
    return out_buffer, fim - inicio

def descriptografar_imagem(chave, arquivo):
    inicio = time.perf_counter()
    chave.seek(0)
    arquivo.seek(0)
    aes_key = chave.read()
    enc_bytes = arquivo.read()

    nonce = enc_bytes[:16]
    tag = enc_bytes[16:32]
    ciphertext = enc_bytes[32:]
    cipher_aes = AES.new(aes_key, AES.MODE_EAX, nonce)
    decrypted_data = cipher_aes.decrypt_and_verify(ciphertext, tag)
    buffer = io.BytesIO(decrypted_data)
    fshift_restaurado = np.load(buffer)
    fim = time.perf_counter()
    return fshift_restaurado, fim - inicio


def ifft(fshift):
    imagem_restaurada = np.abs(np.fft.ifft2(np.fft.ifftshift(fshift)))
    imagem_restaurada_uint8 = cv2.normalize(imagem_restaurada, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    return imagem_restaurada_uint8

# ----------------- INTERFACE -----------------
st.caption("Nikato Productions")
image = Image.open("banner.jpg")
st.image(image, use_container_width=True)

st.title("Fake-DICOM: Detec√ß√£o de Anomalias em Imagens M√©dicas")

# ----- ESTAT√çSTICAS -----
st.subheader("Estat√≠sticas da Criptografia")
st.caption("√öltimo teste realizado com o algoritmo AES para gera√ß√£o de estat√≠sticas: 10/05/2025")
df = pd.read_excel('cripto.xlsx')
st.dataframe(df.describe())

fig, ax = plt.subplots(figsize=(12, 5))
ax.plot(df['slice'], df['tempoExecucaoAES'], color='blue')
ax.set_title('Execu√ß√£o da Criptografia por Slice - 1799 Slices')
ax.set_xticks([])
ax.tick_params(axis='y', labelsize=10)
ax.set_xlabel('Slice', fontsize=10)
ax.set_ylabel('Tempo de Execu√ß√£o (s)', fontsize=10)
ax.legend(['Tempo de Execu√ß√£o'])
st.pyplot(fig)

st.markdown("---")

# ----- UPLOAD DE IMAGEM -----
st.title("Upload de Imagem PNG")
arquivo_imagem = st.file_uploader("Escolha um arquivo PNG para ser analisado", type=["png"])

if arquivo_imagem:
    imagem_upload = Image.open(arquivo_imagem)
    imagem_np = np.array(imagem_upload)
    imagem = cv2.resize(imagem_np, (512, 512), interpolation=cv2.INTER_AREA)
    f = np.fft.fft2(imagem)
    fshift = np.fft.fftshift(f)

    mag_spec = 20 * np.log(np.abs(fshift) + 1)
    mag_spec_norm = cv2.normalize(mag_spec, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    st.success("Imagem carregada com sucesso e Transformada para o dom√≠nio da frequ√™ncia!")
    col1, col2 = st.columns(2)
    with col1:
        st.image(imagem, caption="Imagem carregada", use_container_width=True)
    with col2:
        st.image(mag_spec_norm, caption="Espectro Gerado", use_container_width=True)

    st.markdown("---")

# ----- CRIPTOGRAFIA -----
    st.header("üîê Criptografia AES!")
    if 'aes_key' not in st.session_state:
        st.session_state.aes_key = get_random_bytes(32)

    st.markdown('<h4>üîë Sua chave de Criptografia AES (salve):</h4>', unsafe_allow_html=True)
    st.code(st.session_state.aes_key.hex(), language="text")

    st.download_button("üîë Baixar Chave de Criptografia", st.session_state.aes_key, "aes_key.pem", "application/octet-stream")
    
    st.markdown("---")
    st.markdown('### ‚ñ∂Ô∏è Executar!')
    if st.button("üîí Executar Criptografia"):
        cripto, tempo = criptografar_imagem(fshift, st.session_state.aes_key)
        st.session_state.cripto = cripto
        st.session_state.tempo_cripto = tempo

    if 'cripto' in st.session_state:
        st.markdown('<h4>üîí 30 primeiros bytes do arquivo criptografado (salve):</h4>', unsafe_allow_html=True)
        st.code(st.session_state.cripto.getvalue()[:30], language="text")

        st.download_button("üóÉÔ∏è Baixar Arquivo Criptografado (.enc)", st.session_state.cripto, "imagem_criptografada.enc", "application/octet-stream")
        st.success(f"‚úÖ Criptografia conclu√≠da em {st.session_state.tempo_cripto:.4f} segundos.")

    st.markdown("---")

# ----- DESCRIPTOGRAFIA -----
    st.header("üîì Descriptografia AES!")
    st.markdown('<h4>üîë Insira a Chave para Descriptografia</h4>', unsafe_allow_html=True)
    chave_descript = st.file_uploader("Chave", type=["pem"])

    st.markdown('<h4>üóÉÔ∏è Insira o Arquivo Criptografado</h4>', unsafe_allow_html=True)
    enc_file = st.file_uploader("Arquivo Criptografado", type=["enc"])


    if chave_descript and enc_file:
        try:
            fshift_restaurado, tempo_decript = descriptografar_imagem(chave_descript, enc_file)
            st.success(f"‚úÖ Descriptografia conclu√≠da em {tempo_decript:.4f} segundos.")

            col_central = st.columns([1, 2, 1])[1]
            with col_central:
                st.subheader('Imagem Restaurada!')
                st.image(ifft(fshift_restaurado), width=300)
        except Exception as e:
            st.error(f"‚ùå Erro na descriptografia: {e}")

    st.markdown("---")
    
# ----- INICIAR CNN -----
    if st.button("Iniciar CNN"):
        st.session_state.cnn_ativa = True

    if st.session_state.cnn_ativa:
        st.subheader("üîç An√°lise de Seguran√ßa com MobileNet")
        
        col1, col2 = st.columns(2)
        with col1:
            st.image(imagem, caption="Imagem Original", use_container_width=True)
        with col2:
            st.image(mag_spec_norm, caption="Espectro de Frequ√™ncia", use_container_width=True)
    
        st.markdown("### üéØ Simular Ataque em Regi√£o Espec√≠fica")
        cols = st.columns(4)
        corners = {
            "Superior Esquerdo": 0,
            "Superior Direito": 1,
            "Inferior Esquerdo": 2,
            "Inferior Direito": 3
        }
    
        for i, (label, corner) in enumerate(corners.items()):
            if cols[i].button(label):
                modified_fshift, mag_spec = freq_spec(fshift, imagem, threshold_percent=0.1, sigma_blur=0.8, add_noise=True, corner=corner)
                img_hacked = ifft(modified_fshift)

                sample_image = mag_spec.astype('uint8')
                sample_image = preprocessar_imagem(sample_image)
                sample_image_exp = np.expand_dims(sample_image, axis=0)

                predicao = modelo_MobileNet.predict(sample_image_exp)
                classe = np.argmax(predicao)
                confianca = predicao[0][classe]
                
                heatmap = gerar_heatmap(modelo_MobileNet, sample_image_exp)
    
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.image(img_hacked, caption="Imagem Retransformada (IFFT)", use_container_width=True)
                with col2:
                    st.image(sample_image, caption="Entrada da CNN", use_container_width=True)
                with col3:
                    st.image(heatmap, caption="Mapa de Ativa√ß√£o", use_container_width=True)
    
                st.markdown(f"**Diagn√≥stico:** {'üö® Hackeada' if classe == 1 else '‚úÖ Normal'} "
                            f"(Confian√ßa: {confianca*100:.2f}%)")

st.markdown("""<hr style="border:1px solid gray">""", unsafe_allow_html=True)
st.caption("TCC - Ci√™ncia da Computa√ß√£o - FEI")
st.caption("Projeto desenvolvido por Gabriel N. Missima, Vinicius A. Pedro, Carlos M. H. Chinen")
st.caption("Orientador: Prof. Dr. Paulo S√©rgio")
